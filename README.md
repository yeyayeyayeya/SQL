# ğŸ“ Student Grade Management â€“ ETL Pipeline

An end-to-end ETL pipeline built using **Python**, which extracts student data from **SQL Server**, transforms it to calculate GPA and academic ranking, and loads it into a **PostgreSQL** data warehouse. The result is also exported as a CSV file, which can be used for reporting and dashboarding.

---

## âœ¨ Project Overview

This project simulates a real-world student grade management system where you:

- Extract raw data from SQL Server tables: students, subjects, and scores.
- Clean and transform the data:
  - Normalize student names
  - Handle missing values (optional)
  - Compute GPA
  - Classify academic performance (`Giá»i`, `KhÃ¡`, `Trung BÃ¬nh`, `Yáº¿u`)
- Load the final report into:
  - PostgreSQL table: `bang_tong_hop`
  - CSV file: `D:/DB/output.csv`

---

## ğŸ§± Technologies Used

- **Python 3.10+**
- **pandas** for data transformation
- **SQLAlchemy** & **psycopg2** for PostgreSQL connection
- **pyodbc** for connecting to SQL Server
- **PostgreSQL** as the data warehouse
- *(Optional)*: Metabase / Power BI for dashboarding

---

## ğŸ“‚ Project Structure

student-grade-management/
â”œâ”€â”€ etl.py                  # Main ETL script
â”œâ”€â”€ migrate_all.py          # Optional: Copy source tables to PostgreSQL
â”œâ”€â”€ config.py.example       # Sample config (hide real credentials)
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ requirements-dev.txt    # Dev/test dependencies
â”œâ”€â”€ schema_postgres.sql     # PostgreSQL-compatible schema
â”œâ”€â”€ schema_mssql.sql        # SQL Server-compatible schema
â”œâ”€â”€ data/
â”‚   â””â”€â”€ output.csv          # Final report after transformation
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_etl.py         # Unit tests for ETL pipeline
â””â”€â”€ README.md               # You're reading it!

---

## ğŸ”§ Setup Instructions

1. ğŸ“¥ Clone the repository
```bash
git clone https://github.com/yeyayeyayeya/SQL.git
cd SQL
git checkout student-grade-management
```

2. ğŸ“¦ Install dependencies
```bash
# For main ETL pipeline (production use)
pip install -r requirements.txt

# For development & testing environment:
pip install -r requirements-dev.txt
```

3. âš™ï¸ Configure database connections
Create a `config.py` file based on the sample:
```python
SQL_SERVER_CONN_STR = (
    "DRIVER={ODBC Driver 17 for SQL Server};"
    "SERVER=YOUR_SQL_SERVER_NAME\\INSTANCE;"  # Replace with your actual SQL Server
    "DATABASE=YOUR_SQL_DATABASE;"
    "Trusted_Connection=yes;"  # Use this if connecting via Windows Authentication
    # Or use SQL Server Authentication:
    # "UID=your_username;PWD=your_password;"
)

POSTGRES_CONN_STR = "postgresql+psycopg2://your_user:your_password@localhost:5432/YOUR_POSTGRES_DB"
```
> ğŸ” Important: Avoid committing actual credentials. Use environment variables or a `.env` file in production.

4. ğŸš€ Run the ETL pipeline
```bash
python etl.py
```

The ETL pipeline will:
- âœ… Extract data from SQL Server (`DMSV`, `DMMH`, `KETQUA`)
- âœ… Calculate GPA and classify academic performance
- âœ… Merge into final report
- âœ… Load into PostgreSQL as `bang_tong_hop`
- âœ… Export to CSV at `D:/DB/output.csv`

5. ğŸ”„ (Optional) Migrate all source tables to PostgreSQL
```bash
python migrate_all.py
```

6. âœ… Sample Output
```
| MaSV | HoTen           | MaMH | TenMH      | Diem | LanThi | GPA  | XepLoai     |
|------|------------------|------|------------|------|--------|------|-------------|
| 001  | Le Van An        | MH01 | Math       | 8.5  | 1      | 8.33 | Excellent    |
| 002  | Nguyen Thi Bich  | MH02 | Physics    | 6.0  | 1      | 6.00 | Average      |
| 003  | Tran Minh Cuong  | MH03 | Chemistry  | 7.0  | 2      | 7.50 | Good         |
```

7. ğŸ§ª Run Unit Tests
```bash
pytest tests/test_etl.py
```
Tests include:
- âœ… Extraction from SQL Server
- âœ… GPA and ranking logic
- âœ… Column name validation
- âœ… Transformation correctness
- âœ… PostgreSQL data load
- âœ… Full ETL pipeline execution

8. ğŸ“ˆ Future Improvements
- â• Add more test coverage (e.g. null handling, edge cases)
- ğŸ“Š Connect to Metabase or Power BI for dashboard visualization
- â° Automate with cron jobs or pgAgent
- ğŸ” Move credentials to `.env` file for better security
- ğŸ“¦ Package ETL into a reusable module or CLI tool
